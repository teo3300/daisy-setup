# vim:foldmethod=marker:fmr=<<<,>>>

# Networks definition <<<
networks:
  frontend:
    driver: bridge
  nextcloud-backend:
    driver: bridge
  gitea-backend:
    driver: bridge
  synapse-backend:
    driver: bridge
  jellyfin-backend:
    driver: bridge
  vikunja-backend:
    driver: bridge
# >>>

services:

# Reverse proxy (traefik) <<<
  traefik:
    image: traefik:latest
    restart: unless-stopped
    container_name: 'traefik'
    profiles:
      - network-alt
    #  - network
    #  - core
    ports:
      - '80:80'
      - '443:443'
    # Web-UI
      - '8080:8080'
    networks:
      - frontend
    volumes:
      - ~/traefik:/etc/traefik:ro
      - ~/docker/traefik/ssl-certs:/ssl-certs
    # to listen to docker events
      - /var/run/docker.sock:/var/run/docker.sock
    # set timezone and localtime as the machine settings
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro

# >>>

# Web server and reverse proxy (nginx) <<< 
  nginx:
    image: nginx:latest
    restart: unless-stopped
    container_name: nginx
    profiles:
      - network
      - core
    ports:
      - 80:80
      - 443:443
    networks:
      - frontend
    environment:
      SERVER_DOMAIN: '${SERVER_DOMAIN}'
    volumes:
      # Write only the config file (temporary)
      - ~/nginx/nginx.conf:/etc/nginx/template-nginx.conf:ro
      - ~/nginx/makeconf.sh:/docker-entrypoint.d/99_makeconf.sh
      # /var/www/certbot is only used for the acme challenge
      - ~/docker/certbot/www:/var/www/certbot:ro
      - ~/docker/certbot/conf:/etc/letsencrypt:ro
      # Expose logs for fail2ban
      # - /var/log/nginx:/var/log/nginx
      # Use host's timezone
      - /etc/timezone:/etc/timezone:ro

##  fail2ban:
##    image: crazymax/fail2ban:latest
##    container_name: fail2ban
##    restart: unless-stopped
##    network_mode: "host"
##    profiles:
##      - network-alt
##    cap_add:
##      - NET_ADMIN
##      - NET_RAW
##    volumes:
##      - ~/docker/fail2ban:/data
##      # Read nginx logs (and only nginx logs)
##      - /var/log:/var/log:ro
##      # Use host's timezone
##      - /etc/timezone:/etc/timezone:ro
##      - /etc/localtime:/etc/localtime:ro
##    environment:
##      F2B_LOG_TARGET: STDOUT
##      F2B_LOG_LEVEL: INFO
  # Certbot container for certificate renewal
  certbot:
    image: certbot/certbot
    restart: no
    container_name: certbot
    profiles:
      - dummy
    volumes:
      - ~/docker/certbot/www:/var/www/certbot
      - ~/docker/certbot/conf:/etc/letsencrypt
      # to use correct timezone
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    # Renew noninteractively (expect an external container running a web server)
    command: 'renew --webroot -w /var/www/certbot -n' 

  # Certbot container for creating a new, non-existing certificate, must be run specifying the $SERVER_SUBDOMAIN
  certbot-new:
    image: certbot/certbot
    restart: no
    container_name: certbot-new
    profiles:
      - dummy
    ports:
      - 80:80
    volumes:
      - ~/docker/certbot/www:/var/www/certbot
      - ~/docker/certbot/conf:/etc/letsencrypt
      # to use correct timezone
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    # Does not require an external webserver
    command: 'certonly --standalone --email ${CERTBOT_EMAIL} --domain ${SERVER_SUBDOMAIN} --agree-tos -n'

# >>>

# Password manager (bitwarden) <<<
  bitwarden:
    image: vaultwarden/server:latest
    restart: unless-stopped
    container_name: 'bitwarden'
    environment:
      DOMAIN: 'https://bitwarden.${SERVER_DOMAIN}'
    profiles:
      - service
      - core
    volumes:
      - ~/docker/vw-data:/data
    networks:
      - frontend
# >>>

# Local DNS (pihole) <<<
  pihole:
    image: pihole/pihole:latest
    restart: unless-stopped
    container_name: 'pihole'
    profiles:
      - network
      - core
    ports:
      - '53:53/tcp'
      - '53:53/udp'
      - '67:67/udp'
      ## Do not proxy-manage dashboard
      - '8081:80/tcp'
    volumes:
      - ~/docker/pihole/etc/pihole:/etc/pihole
      - ~/docker/pihole/etc/dnsmasq.d:/etc/dnsmasq.d
    environment:
      TZ: 'Europe/Rome'
      WEBPASSWORD: '${PIHOLE_WEBPASSWORD}'
    networks:
      - frontend
# >>>

# Media streaming (jellyfin) <<<

  # Application (jellyfin) <<<
  jellyfin:
    image: 'jellyfin/jellyfin'
    restart: unless-stopped
    container_name: 'jellyfin'
    profiles:
      - service
      - intensive
      - jellyfin
    user: 1000:1000
    volumes:
      - ~/docker/jellyfin/config:/config
      - ~/docker/jellyfin/cache:/cache
      - type: bind
        source: ~/docker/jellyfin/media
        target: /media
        read_only: true
      - type: bind
        source: ~/docker/jellyfin/media2
        target: /media2
        read_only: true
      - type: bind
        source: ~/docker/jellyfin/fonts
        target: /usr/local/share/fonts/custom
        read_only: true
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    environment:
      JELLYFIN_PublishedServerUrl: 'movie.${SERVER_DOMAIN}'
      TZ: Europe/Rome
    extra_hosts:
      - 'host.docker.internal:host-gateway'
    networks:
      - jellyfin-backend
      - frontend
  # >>>
##
##  # Indexer (prowlar) <<<
##  prowlarr:
##    image: ghcr.io/hotio/prowlarr
##    container_name: prowlarr
##    ports:
##      - '9696:9696'
##    profiles:
##      - services
##      - jellyfin
##    environment:
##      PUID: 1000
##      PGID: 1000
##      UMASK: 002
##      TZ: Europe/Rome
##    volumes:
##     - ~/docker/prowlarr/config:/config
##    networks:
##      - jellyfin-backend
##      - frontend
##  # >>>
##
##  # TV-series manager (sonarr) <<<
##  sonarr:
##    image: ghcr.io/hotio/sonarr
##    container_name: sonarr
##    ports:
##      - "8989:8989"
##    profiles:
##      - services
##      - jellyfin
##    environment:
##      PUID: 1000
##      PGID: 1000
##      UMASK: 002
##      TZ: Europe/Rome
##    volumes:
##      - ~/docker/sonarr/config:/config
##      - ~/docker/sonarr/data:/data
##      - ~/docker/jellyfin/media:/media
##    networks:
##      - jellyfin-backend
##      - frontend
##  # >>>
##
# >>>

# Drive (nextcloud) <<<
  # Database (mariadb) <<<
  nextcloud-db:
    image: mariadb:10.6
    container_name: 'nextcloud-db'
    restart: unless-stopped
    command: --transaction-isolation=READ-COMMITTED --log-bin=binlog --binlog-format=ROW
    profiles:
      - service
      - core
      - intensive
      - nextcloud
    volumes:
      - ~/docker/nextcloud/db:/var/lib/mysql
    healthcheck:
      test: ["CMD-SHELL", "mysqladmin ping -h localhost -u $$MYSQL_USER --password=$$MYSQL_PASSWORD"]
      interval: 10s
      start_period: 10s
    environment:
      MYSQL_ROOT_PASSWORD: '${NEXTCLOUD_DB_ROOT_PASSWORD}'
      MYSQL_PASSWORD: '${NEXTCLOUD_DB_PASSWORD}'
      MYSQL_DATABASE: nextcloud
      MYSQL_USER: nextcloud
    networks:
      - nextcloud-backend
  # >>>

  # Frontend (nextcloud) <<<
  nextcloud-frontend:
    image: nextcloud:latest
    restart: unless-stopped
    container_name: nextcloud-frontend
    profiles:
      - service
      - core
      - intensive
      - nextcloud
    volumes:
      - ~/docker/nextcloud/app:/var/www/html
    environment:
      # DB config
      MYSQL_PASSWORD: '${NEXTCLOUD_DB_PASSWORD}'
      MYSQL_DATABASE: nextcloud
      MYSQL_USER: nextcloud
      MYSQL_HOST: nextcloud-db
      # Redis config
      REDIS_HOST: nextcloud-redis
      REDIS_HOST_PASSWORD: '${NEXTCLOUD_REDIS_PASSWORD}'
      # Additional conf (these are the same ase config.php)
      NEXTCLOUD_TRUSTED_DOMAINS: 'drive.${SERVER_DOMAIN}'
      # Refresh htaccess container init
      NEXTCLOUD_INIT_HTACCESS: true
      # Apache config
      DISABLE_REWRITE_IP: 1
      TRUSTED_PROXIES: '${NEXTCLOUD_TRUSTED_PROXIES}'
      OVERWRITEPROTOCOL: https
      OVERWRITECLIURL: 'https://drive.${SERVER_DOMAIN}'

    depends_on:
      nextcloud-db:
        condition: service_healthy
      nextcloud-redis:
        condition: service_healthy
    networks:
      - nextcloud-backend
      - frontend
  # >>>
  
  # File locking (redis) <<<
  nextcloud-redis:
    image: redis:alpine
    restart: unless-stopped
    container_name: nextcloud-redis
    profiles:
      - service
      - core
      - intensive
      - nextcloud
    networks:
      # Expose via host for now
      - nextcloud-backend
    command: '--requirepass ${NEXTCLOUD_REDIS_PASSWORD}'
    healthcheck:
      interval: 30s
      start_period: 30s
      test: ["CMD-SHELL", "redis-cli", "--raw", "incr", "ping"]

  # >>>

# >>>

# ToDoList (vikunja) <<<
  # Frontend (vikunja) <<<
  vikunja-frontend:
    image: vikunja/vikunja
    restart: unless-stopped
    container_name: 'vikunja-frontend'
    profiles:
     - service
    environment:
      VIKUNJA_SERVICE_PUBLICURL: 'https://todo.${SERVER_DOMAIN}'
      VIKUNJA_DATABASE_HOST: vikunja-db
      VIKUNJA_DATABASE_PASSWORD: '${VIKUNJA_DB_PASSWORD}'
      VIKUNJA_DATABASE_TYPE: mysql
      VIKUNJA_DATABASE_USER: vikunja
      VIKUNJA_DATABASE_DATABASE: vikunja
      VIKUNJA_SERVICE_JWTSECRET: '${VIKUNJA_JWT_PASSWORD}'
      VIKUNJA_SERVICE_ENABLEREGISTRATION: false
      VIKUNJA_SERVICE_TIMEZONE: Europe/Rome
    depends_on:
      vikunja-db:
        condition: service_healthy
    networks:
      - vikunja-backend
      - frontend
  # >>>

  # Database (mariadb) <<<
  vikunja-db:
    image: mariadb:10
    restart: unless-stopped
    container_name: 'vikunja-db'
    command: --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci
    profiles:
      - service
    environment:
      MYSQL_ROOT_PASSWORD: '${VIKUNJA_DB_ROOT_PASSWORD}'
      MYSQL_USER: vikunja
      MYSQL_PASSWORD: '${VIKUNJA_DB_PASSWORD}'
      MYSQL_DATABASE: vikunja
    volumes:
      - ~/docker/vikunja/db:/var/lib/mysql
    healthcheck:
      test: ["CMD-SHELL", "mysqladmin ping -h localhost -u $$MYSQL_USER --password=$$MYSQL_PASSWORD"]
      interval: 30s
      start_period: 30s
    networks:
      - vikunja-backend
  # >>>
# >>>

# Matrix (synapse) <<<
  synapse-frontend:
    container_name: synapse-frontend
    image: docker.io/matrixdotorg/synapse:latest
    restart: unless-stopped
    profiles:
      - service
    environment:
      UID: 1000
      GID: 1000
      SYNAPSE_CONFIG_PATH: /data/homeserver.yaml
    depends_on:
      synapse-db:
        condition: service_healthy
    volumes:
      - ~/docker/synapse/data:/data
    networks:
      - frontend
      - synapse-backend

  synapse-db:
    image: postgres:15-alpine
    container_name: synapse-db
    restart: unless-stopped
    profiles:
      - service
    volumes:
      - ~/docker/synapse/db:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -d $$POSTGRES_DB -U $$POSTGRES_USER"]
      interval: 30s
      start_period: 30s
    environment:
      POSTGRES_USER: 'synapse_user'
      POSTGRES_PASSWORD: '${SYNAPSE_DB_PASSWORD}'
      POSTGRES_DB: 'synapse'
      POSTGRES_INITDB_ARGS: '--encoding=UTF-8 --lc-collate=C --lc-ctype=C'
    networks:
      - synapse-backend
# >>>

# Git (gitea) <<<
  gitea-frontend:
    container_name: gitea-frontend
    image: docker.gitea.com/gitea:1.24.2-rootless
    profiles:
      - service
      - gitea
    #  - core
    restart: always
    environment:
      GITEA__database__DB_TYPE: 'postgres'
      GITEA__database__HOST: 'gitea-db:5432'
      GITEA__database__NAME: 'gitea'
      GITEA__database__USER: 'gitea'
      GITEA__database__PASSWD: '${GITEA_DB_PASSWORD}'
      GITEA__server__DOMAIN: 'git.${SERVER_DOMAIN}'
      GITEA__server__ROOT_URL: 'https://git.${SERVER_DOMAIN}/'
      GITEA__server__SSH_DOMAIN: 'git.${SERVER_DOMAIN}'
    ## Should be in container's /etc/gitea/conf/app.ini
    #  DISABLE_REGISTRATION: true
    ports:
      - '2222:2222'
    depends_on:
      gitea-db:
        condition: service_healthy
    volumes:
      - ~/docker/gitea/data:/var/lib/gitea
      - ~/docker/gitea/config:/etc/gitea
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    networks:
      - frontend
      - gitea-backend

  gitea-db:
    image: postgres:17
    container_name: gitea-db
    restart: always
    profiles:
      - service
      - gitea
    #  - core
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -d $$POSTGRES_DB -U $$POSTGRES_DB"]
      interval: 10s
      start_period: 10s
    volumes:
      - ~/docker/gitea/db:/var/lib/postgresql/data
    environment:
      POSTGRES_USER: 'gitea'
      POSTGRES_PASSWORD: '${GITEA_DB_PASSWORD}'
      POSTGRES_DB: 'gitea'
    networks:
      - gitea-backend
# >>>

# Docker cockpit (portainer) <<<
  portainer:
    container_name: portainer
    image: portainer/portainer-ce:lts
    restart: always
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ~/docker/portainer:/data
    profiles:
      - service
    networks:
      - frontend
# >>>

# >>>
